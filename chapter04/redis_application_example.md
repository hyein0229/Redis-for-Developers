# 4장 레디스 자료구조 활용 사례
## sorted set 을 이용한 실시간 리더보드 (랭킹 시스템)
- 리더보드? 경쟁다르의 순위와 현재 점수를 보여주는 순위표를 말함
- 주로 스코어로 정렬하여 상위의 순위를 보여줄 때
- ex. 듀오링고
    - 학습 애플리케이션에서도 학습 데이터를 기반으로 게임화하여 리더보드 기능 제공
    - 경쟁으로 참여도 향상
- 리더 보드의 두 가지 유형
    - 절대적 리더보드: 서비스의 '모든 유저'를 대상으로 정렬하여 상위권만 보임
    - 상대적 리더보드: 사용자마다 다른 데이터가 보임 ex. 유저와 인접한 경쟁자들 보여주기, 유저가 속한 그룹 내 랭킹
- 리더 보드의 요구사항
    - 사용자가 증가할 수록 데이터 연산이 몇 배로 증가하므로 이러한 계산이 빠르게 되어야 함
    - 실시간으로 데이터가 추가되면 실시간 정렬되어 보여주어야 함
    - 상대적 리더보드인 경우 다양한 그룹의 관점에서 데이터 계산, 통계가 필요함
    - 이걸 RDB 로 한다면? 실시간 업데이트와 정렬 작업 자체가 DB 에 상당한 부하를 준다.

___

### 단순 일별 리더보드
ZADD 로 유저 데이터 추가, `ZREVRANGE` 로 상위 경쟁자 출력
```shell
> ZADD daily-score:220817 28 player:286 
> ZREVRANGE daily-score:220817 0 2 withscores # 스코어가 높은 순으로 상위 3개 출력
``` 
ZADD 는 아이템 저장 및 기존 아이템이 있다면 데이터 업데이트가 가능하다.

만약, 직접 스코어 값을 지정해서 변경하지 않고 증감 계산을 사용하고 싶다면 `ZINCRBY` 을 사용하면 된다.
```shell
> ZINCRBY daily-score:220817 100 player:24 # 100만큼 스코어 증가
```

___

### 랭킹 합산
- 만약, 주간 리더보드를 보여주어야 한다면?
- 일주일에 해당하는 모든 날짜의 키의 스코어를 합해서 보여주어야 한다.

`ZUNIONSTORE` 커맨드로 쉽게 각 키의 스코어를 합칠 수 있음
```
ZUNIONSTORE [생성할 키 이름] [합산할 키 개수] [합산할 키...]
```
```shell
> ZUNIONSTORE weekly-score:2208-3 3 daily-score:220815 daily-score:220816 daily-score:220817
```
만약, 어떤 특정 날의 스코어는 2배를 주는 이벤트가 있다면 가중치를 주어 합산할 수도 있다.

```shell
> ZUNIONSTORE weekly-score:2208-3 3 daily-score:220815 daily-score:220816 daily-score:220817 weights 1 2 1 # 데이터를 합칠 때 가중치를 줄 수 있다.
```

## sorted set 을 이용한 최근 검색 기록 
- 만약, 사용자가 최근에 검색한 내역을 보여주는 기능이 있다면
- 최근 검색 기록의 요구사항
    - 유저별로 다른 키워드 노출
    - 검색 내역은 중복 제거
    - 가장 최근 검색된 5개의 키워드만 노출
- 만약 RDB 로 만든다면 어떤가
    - select order by 로 최근 5개 검색된 데이터 조회, sorting 필요
    - 데이터를 insert 할 때도 같은 키워드가 검색되었는지 확인 작업이 필요
    - 테이블에 오래된 데이터가 무기한으로 쌓이지 않도록 주기적으로 제거하는 배치 작업 필요
- sorted set 은 빠르고, 중복을 자동 제거하고, 자동 정렬해준다.

스코어를 **유저가 검색한 시간** 으로 저장한다면 검색 시간 순으로 자동 정렬된다.
```shell
> ZADD search-keyword:123 20221106143501 코듀로이
(integer) 1
> ZREVRANGE search-keyword:123 0 4 withscores # 최근 검색된 5개 조회
...
```

만약, 최근 5개의 검색어만 남기고 삭제하고 싶다면?<br>
0번 인덱스 (즉, -6번 인덱스) 데이터 삭제하는 작업을 데이터를 넣을 때 같이 수행하면 된다.
```shell
> ZADD search-keyword 20221106165302 복숭아
1

> ZREMRANGEBYRANK search-keyword -6 -6 
1
```
- 0번 인덱스 제거 vs -6번 인덱스 제거
    - 0번 인덱스를 제거하려면 아이템의 개수가 5개를 넘었는지를 확인해주고 작업해야 한다.
    - 반면, -6번 인덱스 제거는 어차피 -6번이 없다면 제거가 안되고 있다면 제거되므로 좀더 단순화 가능
- `ZREMRANGEBYRANK key start stop`
    - 인덱스 범위로 아이템 삭제가 가능
    - start 에서 stop 까지 아이템 삭제
    - 만약 이때 아이템의 개수가 5개보다 많지 않다면 -6번째는 존재하지 않으므로 삭제된 데이터가 없다. 

## set 을 이용한 태그 기능
- ex. 블로그 게시물에 여러 태그 달 때
- 만약, RDB 로 구현한다면?
    - 최소 2개의 테이블이 필요하다. 
    - 태그 테이블과 태그-게시물 테이블(중간테이블)
- 태그 기능의 요구사항
    - 특정 게시물이 어떤 태그와 연관되어 있는지 확인할 수 있어야 함
    - 특정 태그를 포함한 게시물만 확인할 수 있어야 함

```shell
> SADD post:27:tags IT REDIS DateStore # 포스트 별 연관된 태그 삽입
3

> SADD tag:DataStore:posts 27 # 태그 별 연관된 게시물ID 저장
1

> SADD tag:IT:posts 27
1

> SADD tag:MySQL:posts 27
1

> SMEMBERS tag:IT:posts # 특정 태그를 가진 포스트ID 목록 확인
1) "27"
2) "53"
```

여러 태그를 검색했을 때 모든 태그를 공통으로 가지는 포스트를 검색하고 싶다면 `SINTER` 커맨드 사용 

`SINTER` 는 두 set 의 교집합을 확인할 수 있다.
```shell
> SINTER tag:IT:posts tag:DataStore:posts
1) "40"
2) "53"
```

만약, RDB 로 구현한다면 group by - having 절 사용
```sql
select post_id from tag_post where tag_id in (1, 3) group by post_id having count(tag_id) >= 2;
```

## 랜덤 데이터 추출
- 랜덤 데이터 추출 예시
    - 게임에서 랜덤으로 게임 유저를 매핑할 때
    - 이벤트에 응모한 유저를 랜덤으로 추출할 때
    - 랜덤 아이템 뽑기 등
- 만약, RDB 로 구현한다면?
    - `ORDER BY RAND()` 쿼리 사용
    - 조건 절에 맞는 모든 행을 읽고, 임시 테이블에서 랜덤 정렬한 후 limit 까지 데이터 추출
    - 만약, 데이터가 1만 건 이상이라면 쿼리의 성능이 나빠진다.
- redis 사용 시 O(1) 로 랜덤 데이터 추출이 가능
    - `RANDOMKEY` 커맨드는 저장된 전체 키 중 하나를 무작위 반환
    - `HRANDFIELD`: hash 에서 랜덤 아이템 추출
    - `SRANDMEMBER`: set 에서 랜덤 아이템 추출
    - `ZRANDMEMBER`: sorted set 에서 랜덤 아이템 추출

```shell
> HRANDFIELD user:hash # hash 의 key 만 무작위 출력
"Id:4615"

> HRANDFIELD user:hash 1 WITHVALUES # hash 의 key-value 모두 출력
1) "Id:4615"
2) "hyein"

> HRANDFIELD user:hash 2 # 원하는 개수만큼 무작위 추출
1) "Id:4615"
2) "Id:22"

> HRANDFIELD user:hash -2 # 중복 허용하여 무작위 반환
1) "Id:4615"
2) "Id:4615"
```

## 레디스에서의 다양한 카운팅 방법
### 좋아요 카운팅 기능
- 실시간 트래픽이 매우 커서 좋아요가 1초에 몇만개 발생할 수 있다고 하자
- 좋아요 기능이 요구사항
    - 각 데이터의 좋아요 수 카운팅
    - 유저가 중복 좋아요를 하기 않기 위해 유저별 좋아요를 기억해야 함
- 구현
    - `SADD`: 각 키에 좋아요 누른 유저 ID 저장
    - `SCARD`: 좋아요 수 확인 
```shell
> SADD comment-like:12554 967 # 커맨트 별 키에 유저ID 저장
(integer) 1

> SCARD comment-like:12554 # 좋아요 누른 수 확인
(integer) 3
```

___

### 읽지 않은 메시지수 카운팅
- 채팅 애플리케이션에서 사용자가 속한 채널 별 읽지 않은 메시지 수를 확인한다고 하자
- 인메모리에 일시적으로 저장한 뒤 RDB 로 주기적 업데이트 작업을 돌리는게 부하를 최소화하고 성능을 향상시킬 수 있다.
- 기능
    - 단순히 새로 추가된 메시지의 개수를 확인하면 된다.

hash 를 사용하여 각 유저ID 별 키에 [채널ID - 메시지수] 를 저장한다.
```shell
> HINCRBY user:234 channel:4234 1 # 234 번 유저가 4234 채널에서 메시지 수신
(integer) 1
```

만약, 누군가가 전송한 메시지를 삭제했을 땐?
```shell
> HINCRBY user:123 channel:4234 -1 # 누군가 4234 채널에 메시지 삭제
(integer) 26
```

___

### DAU 구하기
- DAU 는 하루 동안 서비스에 방문한 사용자 수로, 여러 번 방문해도 한 번으로 카운팅된다.
- 사용자 접속 로그로 날마다 배치 처리하여 계산하여 DAU 를 구할 수 있지만 실시간성은 부족하다.
- 앞서 좋아요 기능과 같이 set 을 사용하여 구현한다면?
    - 구현 상은 가능하다. 키를 하루일자, 값을 유저 ID 로 한다면
    - 하지만, 만약 1000만 명 이상 유저가 방문하는 규모라면 하나의 키 안에 데이터가 너무 많아진다.
    - 저장되는 데이터가 많아지면 그만큼 엄청난 메모리 차지
    - **보통 키 하나당 저장 아이템 수는 최대 200~300만 개까지로 조정하는 것이 권장된다.**
- 레디스의 bitmap 을 사용하면 메모리를 효율적으로 사용하면서 실시간성을 지킬 수 있다.
    - bitmap 은 별도 자료구조가 아닌 string 자료 구조의 bit 연산을 사용한다.
    - 1000만명 사용자가 있다면, 이를 비트로 나타낸다면 1000만개의 비트로 나타낼 수 있다.
    - 1000만 비트는 대략 1.2MB 크기이므로 최대 512MB 저장이 가능한 string 은 매우 충분하다.

만약, 2025년 8월 11일에 14번 유저가 접근한 경우
```shell
> SETBIT uv:20250811 14 1 # 비트맵의 14번째를 1로 변경
(integer) 0

> BITCOUNT uv:20250811 # 해당 일자에 접속한 유저 수 카운팅
(integer) 90
```

만약, 출석 이벤트를 진행하여 특정 기간 동안 매일 방문한 사용자를 구하고 싶다면? 

BITOP 커맨드로 AND, OR, XOR, NOT 연산을 쉽게 하여 레디스에서 원하는 결과를 바로 가져올 수 있다.
```shell
> BITOP AND event:202508 uv:20250811 uv:20250812 uv:20250813 # 3일 동안 연달아 방문한 유저 수
(integer) 2
```

비트맵의 내용을 확인하고 싶다면? GET 커맨드로 비트맵 결과를 애플리케이션 단에서 가져와서 list 로 변환할 수 있다.

___

### hyperloglog 를 이용한 애플리케이션 미터링
- 미터링?
    - Pay as you go, 즉, 서비스를 사용한 만큼 지불한다는 것을 의미한다.
    - 미터링은 사용자가 얼마나 서비스를 사용했는 지 정확하게 측정할 수 있어야 한다.
    - 클라우드 환경에선 사용자 사용량에 따라 지불이 다르므로 미터링이 매우 중요하다.
- 미터링 솔루션 요구사항
    - 사용자의 서비스 이용 내역을 이용하므로 대용량 데이터 처리가 가능해야 함
    - 서비스 규모에 따라 초당 수천 건 이상의 작업이 발생할 수 있음
    - 높은 처리량과 낮은 대기 시간 처리가 필요
- 다음 조건을 만족한다면 redis 의 hyperloglog 사용을 고려해볼 수 있다.
    - 집합 내의 유일한 데이터의 개수를 카운팅해야 한다. 
    - 1% 미만의 오차는 허용 가능하다.
    - 카운팅할 때 사용한 정확한 데이터를 다시 확인하지 않아도 된다. (즉, 복원 불가)
- hyperloglog 는 정확한 데이터를 기억하지 않아도 된다면 set 대신 효율적인 메모리 사용으로 데이터 개수를 계산할 수 있다.
    - 저장되는 용량은 12KB 로 고정, 최소한의 메모리 사용

hyperloglog 를 사용하여 유저의 월별 API 호출 횟수를 계산한다고 하자.<br>
유저ID 를 키로 사용하고 로그 식별자를 값으로 저장할 수 있다.
```shell
> PFADD 202211:user:245 49394 # 로그 기록
(integer) 1

> PFADD 202211:user:245 32141
(integer) 1

> PFCOUNT 202211:user:245 # 중복되지 않은 데이터 개수 확인
(integer) 2

> PFEMRGE 2022:user:245 202211:user:245 202212:user:245 # 여러 개의 hyperloglog 합치기
"OK"

> PFCOUNT 2022:user:245
(integer) 7
```

`PFMERGE` 커맨드로 여러 개의 hyperloglog 를 합쳐 분기별 또는 연도별 합산 데이터로 쉽게 계산 가능하다.

## Geospatial 사용한 위치 기반 애플리케이션 개발
- 사용자의 위치 데이터가 실시간으로 변할 때 필요한 데이터 저장소의 요구사항
    - 사용자의 현재 위치 파악
    - 사용자의 이동에 따른 실시간 위치 변동 업데이트
    - 사용자의 위치를 기준으로 근처 장소 검색

### 레디스에서의 위치 데이터
- redis 은 geo 자료 구조를 통해서 공간 정보 데이터 저장이 가능하다. 
- 만약 RDB 로 구현한다면
    - 위치 데이터는 저장만 하고, 실제 데이터 가공 및 처리는 저장소 외부에서 이루어져야 한다.
- 장점
    - 모든 데이터는 메모리에 저장되고, 위치 데이터 연산도 내부에서 아주 빠르게 계산될 수 있다.
    - 데이터 이동으로 인한 네트워크 트래픽을 감소
    - 애플리케이션 단에서 계산을 하지 않아도 되므로 복잡성 감소
- geo 와 다른 레디스의 기능과의 조합 사용
    - geo set 과 pub/sub 기능 함께 사용
    - 특정 맛집에서 이벤트를 발생시키면 해당 지역 근처의 사용자에게 실시간 알림을 보내는 서비스

### geo set
- 위치 공간 관리에 특화된 데이터 구조이다.
- 위치 데이터는 경도와 위도 쌍으로 저장되고, 내부적으로는 sorted set 구조로 저장된다.

유저ID 가 142번인 유저의 위치 정보를 `GEOADD` 로 저장하고, `GEOPOS` 로 조회할 수 있다.
```shell
> GEOADD user 127.88 34.33 142 # 데이터 추가

> GEOPOS user 142 # 유저 142번의 위치 가져오기
1) 1) "127.88"
   2) "34.33"
```
만약, 특정 위치 근처의 식당을 찾고 싶다면 `GEOSEARCH` 커맨드를 사용할 수 있다.

```shell
> GEOSEARCH restaurant fromlonlat 126.33 34.22 byradius 1 km # 특정 위치 기준 1km 내 식당
1) "gogi"

> GEOSEARCH restaurant FROMMEMBER pizza BYRADIUS 1 km # FROMMEMBER 사용
1) "gogi"

> GEOSEARCH restaurant FROMLONLAT 126.333 34.223 BYBOX 1500 800 m # BYBOX 가로 1500, 세로 800 m 내 영역
1) "gogi"

```
- `fromlonlat` : 직접 기준이 되는 경도, 위도 좌표 입력
- `frommember` : 동일한 데이터 세트 내에서 검색할 때
- `BYRADIUS` : 지정한 반지름 값을 기준으로 떨어진 범위 내의 데이터 검색
- `BYBOX` : width, height 값을 지정하여 특정 위치 기준으로 한 직사각형 영역 내의 장소들을 검색
    - 이때 기준점을 중심으로 좌우로 width 만큼, 상하로 height 만큼을 포함하는 직사각형 영역이 결정됨
    - 즉, 4 2 km 라면 좌우 2km 내, 상하 1km 내 데이터를 검색하는 것이다
